---
title: 向量化–one-hot编码/数据分箱
date: 2022-12-10 11:12:32
tags: Python面试题
categories: Feature Engineering
cover: https://images.unsplash.com/photo-1666899388931-cb2a70cff398
---

### 为什么使用One-Hot编码？

对于机器学习任务中，特征并不总是连续值，很多是分类值。这些分类值本身没有大小的意义。为了将数据集中一个分类变量替换为一个或多个新特征，我们使用One-Hot编码对数据进行预处理。

因为大部分算法是基于向量空间中的度量来进行计算的，为了使非偏序关系的变量取值不具有偏序性，并且到圆点是等距，从而使用one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用one-hot编码，会让特征之间的距离计算更加合理。离散特征进行one-hot编码后，编码后的特征，其实每一维度的特征都可以看做是连续的特征。就可以跟对连续型特征的归一化方法一样，对每一维特征进行归一化。比如归一化到[-1,1]或归一化到均值为0,方差为1。

#### 为什么特征向量要映射到欧式空间？

​将离散特征通过one-hot编码映射到欧式空间，是因为在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。

#### 什么是One-Hot编码

独热编码即 One-Hot 编码，又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效(即各种属性之间相互排斥)。

简而言之，即把离散的特征的每一种取值都看成一种状态。

这样做的好处主要有：

- 解决了分类器不好处理属性数据的问题

- 在一定程度上也起到了扩充特征的作用

### 为什么要进行分箱操作?

分箱之后，数值型变量的取值空间缩小，也就取值的数量变少了，每个取值的样本量增多，**方差变小，但相应的偏差变大了**，也就是数据所能提供的信息没有分箱前那么精确了。

但是对于分类变量而言，如果类别太多，可能存在个别类别样本量过少，对于数值型变量可能会存在极端值，这都会影响分析的稳健性。这样做可以有助于处理异常值或者样本量较少的值，提高稳定性，并且能够处理与目标变量的非线性关系，从而便于分析，让分析结果或者模型预测更加稳健。

### 常见的特征分箱的方法

根据有无目标变量，特征分箱的方法可分为两种：

- 无监督分箱：如等宽(equal width)、等深\等频（equal depth)、聚类分析等
- 有监督分箱：如决策树、卡方分箱、生存模型分箱、best—KS、遗传算法分箱等。

对于特征的分箱，按步骤可分为两步：

- 细分箱：就是先把原始变量分出一些区间
- 粗分箱：按照临近属性是否相同将相邻的区间进行合并，放到同一类。

### 参考文章

- [数据挖掘过程中特征离散化（分箱）方法介绍 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/486766553)
